% !TeX spellcheck = en_GB
\chapter{The Alexandrov Reflection Method}

\section{Geometry of immersed hypersurfaces (da espandere?)}


The study of immersed hypersurfaces is a fundamental topic in differential geometry, and is especially important in the field of geometric analysis. An immersed hypersurface $X: M^n \rightarrow \overline{M}^{n+1}$ is a submanifold of a higher-dimensional space that is embedded in that space in such a way that the submanifold has the same dimension as the space in which it is embedded minus one. In other words, it is a submanifold of codimension one. We will always assume the embedding to be smooth. The most common case is $\overline{M}^{n+1}=\R^{n+1}$, usually extensively studied in undergraduate courses when $n=2$. We will be assuming that the embedding is also isometric, i.e. the metric $g$ on $M^n$ is the one induced by $(\overline{M}^{n+1}, \overline{g})$. \\
The pullback of the tangent bundle of $\overline{M}^{n+1}$ to
$M^{n}$ is a smooth vector bundle on $M^{n}$:
\begin{align*}
	X^{*}T\overline{M}^{n+1}=T\overline{M}^{n+1}|_{M^n}= \amalg_{p \in M^n} T_p\overline{M}^{n+1}
\end{align*} 

One of the most important concepts in the geometry of immersed hypersurfaces is the concept of a normal vector field. The normal vector field $\nu$ is a section of the pullback vector bundle $X^* TM^{n+1}$ on the manifold $M^n$ that is perpendicular to the tangent space of $M^n$ at each point. At each point $p$:
\begin{align*}
	T_p\overline{M}^{n+1}=T_pM^{n}\oplus N_pM^{n}
\end{align*} 
where $N_pM^{n}$ is the normal vector bundle generated by the normal vector. This also allows us to define the tangent and normal projection on $T\overline{M}^{n+1}|_{M^n}$ by taking the two respective components. 

Clearly, taking $\overline{\nabla}$ to be the Levi-Civita connection on $(\overline{M}^{n+1}, \overline{g})$, we can decompose it as:
\begin{align*}
	\overline{\nabla}_v w = (\overline{\nabla}_v w )^\top +  (\overline{\nabla}_v w )^\bot
\end{align*} 

\begin{defin}
	The {\em second fundamental form} is then defined as: 
	\begin{align*}
	 	\mathrm{I\!I} (v, w) =  (\overline{\nabla}_v w )^\bot 	
	\end{align*} 
\end{defin}
It is a bilinear symmetric tensor because $TM^n$ is involutive in $T\overline{M}^{n+1}$ and depends only on the local value of $v$ and $w$ by symmetry. we can therefore write it as
\begin{align*}
	\mathrm{I\!I} (v, w) = -(h_{ij}v^iw^j)\nu
\end{align*} 
for some matrix $A(p)=\{h_{ij}\}$. we can define the principal curvatures of the hypersurface, as the eigenvalues of this matrix.

It is also possible to check that $(\overline{\nabla}_v w )^\top$ satisfies the definition the Levi-Civita connection on $(M^n, g)$, therefore, from its uniqueness:
\begin{align*}
	\nabla_v w &=  (\overline{\nabla}_v w )^\top	\\
	\overline{\nabla}_v w &= \nabla_v w  + \mathrm{I\!I} (v, w) 
\end{align*} 
where $\nabla$ is the Levi-Civita connection on $(M^n, g)$. This result is known as the {\em Gauss Formula}. It has to be noted however that we are implicitly considering tangent vectors that are not in the same space. Indeed, making that more explicit, the formula should be:
\begin{align*}
	\overline{\nabla}_{X_*v} X_* w &= X_* (\nabla_v w)  + \mathrm{I\!I} (v, w) 
\end{align*}

\begin{proposition}
	\textbf{\em (The Weingarten Equation)} If $v, w \in TM^n$ and $\nu \in NM^n$, if one considers the corresponding derivations in $T\overline{M}^{n+1}$ the following equation holds:
	\begin{align*}
			\left\langle \overline{\nabla}_v \nu, w \right\rangle_{\overline{g}} = - \left\langle \nu, \mathrm{I\!I} (v, w) \right\rangle_{\overline{g}}
	\end{align*}
\end{proposition}
\begin{proof}
	As $\left\langle \nu, w \right\rangle_{\overline{g}}\equiv 0$ on $M$, 
	\begin{align*}
		0&=v\left\langle \nu, w \right\rangle_{\overline{g}}\\
		&=\left\langle  \overline{\nabla}_v \nu, w \right\rangle_{\overline{g}} + \left\langle  \nu, \overline{\nabla}_v w \right\rangle_{\overline{g}}\\
		&=\left\langle \overline{\nabla}_v \nu, w \right\rangle_{\overline{g}} + \left\langle \nu, \mathrm{I\!I} (v, w) \right\rangle_{\overline{g}}
	\end{align*}
	applying the Gauss Formula and the fact that $\nabla_v w \in TM^n$ in the last step
\end{proof}
It is also usual to define the associated Weingarten map, which is the linear map between sections of $M$  $s:\Gamma(M)\rightarrow\Gamma(M)$ satisfying:
\begin{align*}
	\left\langle s(v), w \right\rangle_{g} = \left\langle \nu, \mathrm{I\!I} (v, w) \right\rangle_{\overline{g}}
\end{align*}
the linear map $s$ is also known as the {\em shape operator of $M$}. 

Combining this with the formula above, taking into account that it holds for a generic $w \in TM$:
\begin{align*}
	s(v) = -(\overline{\nabla}_v \nu)^\top
\end{align*}


We are going to use these equations in local coordinates, in the form shown below. 
\begin{proposition}
	The above equations in local coordinates are equivalent to the following equations:
	\begin{align}
		\label{Weingarten1} \frac{\partial^2 X^\alpha}{\partial x^i \partial x^j} - \Gamma^k_{ij}\frac{\partial X^\alpha}{\partial x^k}+\overline{\Gamma}^\alpha_{\beta \delta}\frac{\partial X^\beta}{\partial x^i}\frac{\partial X^\delta}{\partial x^k}=-h_{ij}\nu^\alpha \\
		\label{Weingarten2} \frac{\partial \nu^\alpha}{\partial x^i}+\overline{\Gamma}^\alpha_{\beta \delta}\frac{\partial X^\beta}{\partial x^i} \nu^\delta = h_{ij}g^{jl}\frac{\partial X^\alpha}{\partial x^l}
	\end{align} 
	where $\nu$ is the normal unit vector at the point and $A=\{h_{ij}\}$ is the second fundamental form, thus $h_{ij}= \left\langle  \nu, \overline{\nabla}_{\overline{\partial_i}} \overline{\partial_j} \right\rangle_{\overline{g}} $
\end{proposition}
\begin{proof}
	For any connection $\nabla_\cdot$ and any derivations $v=v^i \partial_i$ and $w=w^j \partial_j$:
	\begin{align*}
		\nabla_{v} w = \nabla_{(v^i \partial_i)} (w^j \partial_j) = v(w^k)\partial_k + (v^i w^j \Gamma^{k}_{ij})\partial_k
	\end{align*}
	Let $\partial_1, \dots \partial_n$ be a basis of $TM^n$ at a point, and let $\overline{\partial_i} = X_*\partial_i$, $\overline{\partial_{n+1}}=\nu$.
	Let's consider the Gauss Formula for two generic $\partial_i$, $\partial_j$, using roman letters for indices varying between $1$ and $n$ and greek letters for indices varying between $1$ and $n+1$, and $\delta^{ij}$ the Kronecker delta:
	\begin{align*}
		\overline{\nabla}_{X_*\partial_i} X_* \partial_j &= X_* (\nabla_{\partial_i} \partial_j)  + \mathrm{I\!I} (\partial_i, \partial_j) \\
		(\overline{\partial_i}(X_*\partial_j)^\alpha) \partial_\alpha + ((X_*\partial_i)^\beta (X_*\partial_j)^\delta \overline{ \Gamma}^{\alpha}_{\beta \delta})\partial_\alpha &= X_* (\cancel{(\partial_i \delta^{jk})\partial_k} +  \delta^{ij}\Gamma^{k}_{ij}\partial_k)  - h_{ij}\nu^\alpha \overline{\partial_\alpha}\\
		(\overline{\partial_i}(X_*\partial_j)^\alpha) \partial_\alpha + ((X_*\partial_i)^\beta (X_*\partial_j)^\delta\overline{ \Gamma}^{\alpha}_{\beta\delta})\partial_\alpha &= X_* (\Gamma^{k}_{ij}\partial_k)  - h_{ij}\nu^\alpha \overline{\partial_\alpha}\\
		\frac{\partial^2 X^\alpha}{\partial x^i \partial x^j} +\overline{\Gamma}^\alpha_{\beta \delta}\frac{\partial X^\beta}{\partial x^i}\frac{\partial X^\delta}{\partial x^k}&=\Gamma^k_{ij}\frac{\partial X^\alpha}{\partial x^k}-h_{ij}\nu^\alpha
	\end{align*}
	Which is the formula (\ref{Weingarten1}). 
	To get the second formula, first note that $s(v) = -(\overline{\nabla}_v \nu)^\top$. We then compute $-\langle s(\partial_i), \overline{\partial_\alpha}\rangle_{\overline{g}}$:
	\begin{align*}
		\left\langle\overline{\nabla}_{\overline{\partial_i}} \nu, \overline{\partial_\alpha}\right\rangle_{\overline{g}} &= -\left\langle s(\partial_i), \overline{\partial_\alpha}\right\rangle_{\overline{g}}\\
		\left\langle \left(\frac{\partial \nu^\alpha}{\partial x^i}+\overline{\Gamma}^\alpha_{\beta \delta}\frac{\partial X^\beta}{\partial x^i} \nu^\delta \right)\overline{\partial_\alpha}, \overline{\partial_\alpha} \right\rangle_{\overline{g}}&= h_{ij}g^{jl}\frac{\partial X^\alpha}{\partial x^l}
	\end{align*}
	leading to (\ref{Weingarten2}).
	\begin{comment}
	Similarly, taking the Weingarten Equation and the definition of $h_{ij}$:
	\begin{align*}
		h_{ij} &=\left\langle  \nu, \overline{\nabla}_{\overline{\partial_i}} \overline{\partial_j} \right\rangle_{\overline{g}} = - \left\langle  \overline{\nabla}_{\overline{\partial_i}} \nu, \overline{\partial_j} \right\rangle_{\overline{g}}\\
		&= - \left\langle \overline{\partial_i}(\nu^\alpha) \overline{\partial_{\alpha}} + ((\overline{\partial_i})^\beta \nu^\delta \Gamma^{\alpha}_{\beta\delta})\overline{\partial_\alpha}, \overline{\partial_j} \right\rangle_{\overline{g}} \\
		&= - \left\langle  (\frac{\partial \nu^\alpha}{\partial x^i}+\overline{\Gamma}^\alpha_{\beta \delta}\frac{\partial X^\beta}{\partial x^i} \nu^\delta )\overline{\partial_\alpha}, \overline{\partial_j} \right\rangle_{\overline{g}}		
	\end{align*}
	Which leads to (\ref{Weingarten2}) by applying the inverse of the metric $g^{jl}$ to both sides. 
	contenuto...
	\end{comment}
\end{proof}


% The Weingarten equations are important in the study of the local properties of immersed hypersurfaces, for example, the second kind equation relates the normal vector field to the shape operator and can be used to compute the mean curvature of the hypersurface. 

% Another important concept in the geometry of immersed hypersurfaces is the Gaussian curvature. The Gaussian curvature is a scalar valued function that describes the total curvature of the hypersurface at each point. It is defined as the product of the eigenvalues of the shape operator and it is closely related to the sectional curvature of the ambient space.

There exist many important partial differential equations (PDEs) which stem from the study of immersed hypersurfaces, for example, the minimal surface equation, which is a PDE that describes surfaces with minimal area, can be seen as a geometric condition on the mean curvature of an immersed hypersurface. Likewise, the mean curvature flow is a geometric flow that deforms an immersed hypersurface by moving each point along the normal vector field at that point by an amount proportional to the mean curvature at that point. This flow is important in the study of geometric PDEs and is used to obtain a lot of important results in differential geometry.

% Some other important results useful for the study of PDEs on immersed manifolds are:


%The Gauss-Codazzi equations: These are a set of equations that relate the curvature of an immersed hypersurface to the curvature of the ambient space. These equations are important in the study of geometric PDEs and are used to obtain a lot of important results in differential geometry.

%The Gauss equation: This is an equation that relates the Gaussian curvature of an immersed hypersurface to the sectional curvatures of the ambient space. It is important in the study of the global properties of immersed hypersurfaces.

%The Gauss-Bonnet theorem: This is a theorem that relates the Gaussian curvature of an immersed hypersurface to the topology of the hypersurface. It is important in the study of the global properties of immersed hypersurfaces and is used to prove many important results in differential geometry.


{\vspace{10pt}\LARGE \bf [Da espandere piÃ¹ avanti, in base a quello che usiamo - forse]}


\section{Local representation as a graph}

A well known result, Dini's Theorem\footnote{also known as Implicit Function Theorem}, states that, given a smooth function $F$ defined on an open subset of the product space $R^n \times R^m$, if $F(x,y) = 0$ and the partial derivative of $F$ with respect to $y$ is nonzero at a point $(x_0, y_0)$, then there exists an open neighborhood of $x_0$ in $R^n$ and a unique smooth function $y = g(x)$ defined on that neighborhood such that $y_0$ is a regular value of $g$ and $(x, g(x))$ is a smooth solution to the equation $F(x, y) = 0$.

Consequence of the Dini's theorem is a powerful result that allows one to locally represent a submanifold of $\R^n \times \R^m$ as the graph of a smooth function. This theorem is widely used in differential geometry, geometric analysis, and many other fields of mathematics and physics. We provide a version of this theorem below:

\begin{theorem}[Local representation as a graph]
	Let $X^n$ be a submanifold $X^n\subset\R^{n+1}$ and let $x_0\in X$. Then there exists a neighbourhood of $x_0$, $U\subset X^n$, such that $U$ is the graph of a function. 
	Moreover, this function can be of the form 
	\begin{align*}
		f:\pi(U)\subset&\R^n\rightarrow U \\
		U=\{(x_0, \dots, x_n)\in \R^{n+1}&|x_0= f(x_1, ..., x_n)\}
	\end{align*}
	for any of the possible orders of the usual basis for $\R^n$, $(e_0, \dots, e_n)$, as long as $e_0\notin T_xM$, where $\pi(U)$ is the projection on the last $n$ coordinates ($(x_0, \dots, x_n) \mapsto (x_1, \dots, x_n)$). \label{localgraphclassic}
\end{theorem}

A proof of the 2D-case of the version of the theorem can be found in \cite{DoCarmo} which extends naturally to the $n$ dimensional case, with almost no changes. This immediately extends to:

\begin{cor}[Local representation as a graph on the tangent]
	Let $X^n$ be a submanifold $X^n\subset\R^{n+1}$ and let $x_0\in X$. Then there exists a neighbourhood of $x_0$ $U\subset X^n$ and a smooth function $f: T_x X^n\rightarrow \R$ such that any $x_0\in U$ can be expressed as \label{localgraphcorollary}
	\begin{align*}
		x_0= p + f(p) \nu 
	\end{align*}
	where $\nu$ is the vector normal to $T_{x_0} X^n$, for an appropriate point $p\in T_{x_0} X^n$. 
	In other words, every submanifold $X^n\subset\R^{n+1}$ is locally expressible as a graph on its tangent space. 
\end{cor}

\begin{proof}
	By rotation, we may assume $T_x X^n$ orthogonal to $e_1$. Then one can just apply the previous theorem. 
\end{proof}

We will use this later to prove Theorem \ref{localgraph}. 


\section{Some well established results from analysis}

We now introduce some well known results from analysis. The first result we introduce is the maximum principle.

The maximum principle is a classical result of mathematical analysis, and it is usually introduced in a first course on partial differential equations. It is a fundamental tool in the theory of partial differential equations. It is a statement about the behavior of solutions to certain types of PDEs and provides a method for obtaining upper and lower bounds on the solutions. The principle states that the maximum and minimum values of a solution to elliptic or parabolic PDE occur on the boundary of the domain unless the function is constant. 

The maximum principle can be used to prove the existence, uniqueness, and regularity of solutions to elliptic and parabolic PDEs. It can also be used to obtain estimates on the behavior of solutions and to study the asymptotic behavior of solutions as the domain becomes large. The principle is widely used in many fields of mathematics and physics, such as geometric analysis, mathematical physics, and fluid dynamics. One of the many versions of this well know theorem is this: 

\begin{theorem}[Maximum principle for parabolic equations]\label{maximum_principle}
	Let $\Omega$ be an open, bounded, connected set. Assume $u\in C^2_1(\Omega\times [0, T])\cap C^1(\overline{\Omega}\times [0, T])$. Suppose $u$ satisfies: 
	\begin{align}
		-\frac{\partial u}{\partial t} + \left(\sum_{i, j=1}^n a_{ij}\frac{\partial^2 }{\partial x_i\partial x_j}+\sum_{i}^n b_{i}\frac{\partial }{\partial x_i} + c\right)  u = -u_t + Lu \geq 0 \label{condition_max_principle}
	\end{align}
	where $L$ is an elliptic differential operator, i.e. there exists $\theta>0$ such that $\sum_{i,j=1}^{n} a_{ij}(x, t) \xi_i\xi_j \geq \theta |\xi |$ for all $\xi \in \R^n$ and $(x, t) \in \Omega\times[0, T]]$. Suppose also that $c\equiv 0$ in $\Omega$. Then: \begin{itemize}
		\item if $u$ attains its maximum in an interior point $(x_0, t_0)\in\Omega\times [0, T]$, then $u$ is constant in $\Omega\times [0, t_0]$.
		\item If, instead, under the same conditions, $u_t+ Lu \geq 0$ and attains its minimum in an interior point of $\Omega\times [0, T]$, then $u$ is constant in $\Omega\times [0, t_0]$
	\end{itemize}
\end{theorem}
A proof of this result can be found, for example, in \cite{Evans}. The theorem extends also to situations where the condition holds in a convex bounded connected region $R\subseteq \Omega \times [0, T]$: in that case, if $u$ attains its maximum in an interior point then $u$ has the same value at any point in $R$ that can be connected to it through a segment going in the backwards direction of time and a "horizontal" line contained in $\Omega$. This version of the theorem can be found for example in \cite{protterweinberger}: 
\begin{theorem}
	Let $u$ satisfy the uniformly parabolic differential inequality (\ref{condition_max_principle}) with $c(x)\leq 0$
	in a region $R_T =\{(x_1,x_2, \dots ,x_n ,t)\vert t\leq T\}$ where $R$ is a non-empty connected open set, and suppose that the coefficients of $L$ are bounded. Suppose that the maximum of $u$ in $R_T$ is $M$ and that it is attained at a point $(x, t)$ of $R_T$. Thus if $(y,s)$ is a point of $R$ which can be connected to $(x,t)$ by a path in $R$ consisting only of horizontal segments and upward vertical segments, then $u(y,s) = M$.\label{maxprincprotterweinberger}
\end{theorem}

Hopf's boundary point lemma is another important classical tool in the study of PDEs that provides a criterion for determining the behavior of solutions to certain types of elliptic or parabolic PDEs near the boundary of the domain. The lemma states that if one has a solutions to some kinds of partial differential inequalities, then the normal derivative of the solution at that point is strictly positive.

It is often used to obtain estimates on the behavior of solutions near the boundary, and to prove the existence and uniqueness of solutions to boundary value problems. The lemma is named after the German mathematician Eberhard Hopf, who first formulated it in the 1950s. In \cite{protterweinberger} we find the following version of the Hopf's boundary point lemma:

\begin{theorem}
	Let u be a solution to the parabolic inequality 
	\begin{align*}
		-u_t+Lu\geq 0
	\end{align*} 
	with $L$ an elliptic linear differential operator with bounded coefficients such that $c(x)\leq 0$,in a domain $E$, and let $E_t = \{(x, s) \in E | s \leq t\}$. Suppose the maximum $M$ of $u$ is attained at a point $P=(x, t)$ on the boundary $\partial E$. \\
	Assume that a sphere through $P$ can be constructed which is in $E_s$ such that
	\begin{itemize}\itemsep0em 
		\item tangent to $\partial E$ at $P$
		\item the set of point of its interior $(y, s)$ such that $s\leq t$ lies in $E_s$, 
		\item  $u < M$ in its interior.
	\end{itemize}	
	Also, suppose that the radial direction from the centre of the sphere to P is not parallel to the t-axis. \\
	Then, if $\frac{\partial}{\partial \nu}$ denotes any directional derivative in an outward direction from $E_s$ , we have
	\begin{align*}
		\frac{\partial u}{\partial \nu} > 0
	\end{align*}
	at P.\label{HopfBPL}
\end{theorem}
\begin{proof}
	Let the sphere through $P$ be $B_1$. We may construct a smaller sphere $B_2$ centred at $P$. Let now:
	\begin{align*}
		S_1 &= \partial B_1 \cap  B_2 \cap E_t, \\
		S_2 &= B_1 \cap \partial  B_2 \cap E_t, \mathrm{ and} \\
		S_3 &= B_1 \cap  B_2 \cap \partial E_t= B_1 \cap  B_2 \cap \{(x, s) \in E | s=t\}.
	\end{align*}
	The three sets satisfy $S_1\cup S_2 \cup S_3 = \partial (B_1 \cap  B_2 \cap E_t)$, we may call this region $R=B_1 \cap  B_2 \cap E_t$. Without loss of generality, potentially taking a smaller sphere $B_1$, we may assume that $u<M$ on $B_1$ except at $P$. As $R \subset B_1$, we also get  $u<M$ on $R$. 
	We may thus conclude that: 
	\begin{itemize}\itemsep0em 
		\item  $u<M$ on $R$ except at $P$
		\item  $u\leq M-\delta$ on $S_2$ for a sufficiently small $\delta>0$
		\item  $u=M$ at $P$.
	\end{itemize}	
	Now, let the centre of $B_1$ be $Q=(z, t_0)$ and let $r$ be its radius. we can now introduce the function	
	\begin{align*}
		v(y, s) = exp \left(-\alpha(s-t_0)^2-\sum_{i=1}^n\alpha(y_i-z_i)^2\right) - exp\left(-\alpha r^2\right)
	\end{align*}
	This function is such that $v(y, s)=0$ if $(y, s)\in S_1$ - including  $v(x, t)=0$, as there the first term is $e^{-\alpha r^2}$, and $v(y, s)>0$ in the interior of $B_1$.  \\
	Thus, in the region $R$, $v(y, s)\geq0$ and has a minimum point at the boundary on $(x, t)$, where  $v(x, t)=0$.
	
	We can also compute $Lv$. After some calculation, we get that 
	\begin{align*}
		Lv = 2 \alpha e^{\left(-\alpha(s-t_0)^2-\sum_{i=1}^n\alpha(y_i-z_i)^2\right)}[2\, \alpha\, (y-z&)^t A (y-z) +\\
		+&\sum_{i}^n[ b_i (y_i-z_i)+a_{i,i}]+(s-t)]
	\end{align*}
	where $A$ is the matrix of the $a_{i,j}$. In particular, one can choose an $\alpha$ large enough, so that $Lv>0$ in $R\cup \partial R$.
	
	We can thus introduce $w=u+\varepsilon v$. As both $Lu$ and $Lv$ are positive in $R$, $Lw>0$ in $R$. We can also choose $\varepsilon$ small enough so that $w<M$ on $S_2$. Also, as $v=0$ on $S_1$, $w<M$ on $S_1$ except at $P$, and $w=M$ at $P$.
	
	Therefore, we can apply the Strong Maximum Principle \ref{maxprincprotterweinberger} to the region $R$ to conclude that the maximum of $w$ in $R$ is attained at $P$. Therefore:
	\begin{align*}
		\frac{\partial w}{\partial \nu}=\frac{\partial u}{\partial \nu}+\varepsilon\frac{\partial v}{\partial \nu}\geq0
	\end{align*}
	But:
	\begin{align*}
		\frac{\partial v}{\partial \nu}=\nu \cdot n\frac{\partial v}{\partial R} = - 2\nu \cdot n \alpha Re^{-\alpha R}<0
	\end{align*}
	Where $n$ is the vector orthogonal to the sphere $S_1$. Therefore, one must have:  
	\begin{align*}
		\frac{\partial u}{\partial \nu}>0
	\end{align*}
	as we wanted.
\end{proof}
\begin{oss}\label{removecpositive}
	\em If $c(x)$ is now just bounded, we can consider, instead of $u$, $v= u e^{-\lambda t}$, thus, by change of variables 
	\begin{align*}
		-v_t+Lv-\lambda v \geq 0
	\end{align*}
	whenever $-u_t+Lu\geq 0$, and we can chose $\lambda$ large enough such that $c(x)-\lambda<0$ and thus we can remove the hypothesis $c(x)\leq0$ in both theorems when $c$ is bounded. 
\end{oss}

\section{Applying the maximum principle to non-linear PDEs}

We can now introduce an important observation shown in \cite{protterweinberger} that allows us to apply the maximum principle \ref{maxprincprotterweinberger} and Hopf's boundary point lemma \ref{HopfBPL} in some non-linear settings.  Firstly, we must clarify what we mean by parabolic non-linear problem. 
\begin{defin}\label{nonlinearpde}
	A differential non-linear problem in the form 
	\begin{align}
		Lu= F\left(t, x, v, \frac{\partial v}{\partial x_i} , \frac{\partial^2 v}{\partial x_i \partial x_j}\right)-v_t = f(x, t)\label{nonlinearexample}
	\end{align} 
	given a smooth $F$ is parabolic if for any real vector $\xi$
	\begin{align*}
		\sum_{i, j=1}^n F_{ij}\xi_i\xi_j >0
	\end{align*} 
	where $F_{ij}$ are the derivatives of $F$ with respect to $\frac{\partial^2 v}{\partial x_i \partial x_j}$. 
\end{defin}
\begin{comment}
	First, let's introduce an easier example from \cite{GidasNirenberg}: 
	Suppose that $u$ solves:
	\begin{align}
		u_t-L u+f(u)=0 \label{non-linear}
	\end{align}
	For an elliptic operator $L$, and where $u_t=\frac{\partial u}{\partial t}$. We note that this differs from the usual parabolic equation because here $f$ depends from the solution $u$, potentially in non-trivial ways, making the equation non-linear. 
	If a solution exists, and $f$ is a $C^1$ function, by the theorem of the mean, at any point $x$ in the domain of $u$ we can find a function $\xi(x)$ such that
	\begin{align*}
		f'(\xi(x))&=\frac{f(u(x))-f(0)}{u(x)-0}\\
		f'(\xi(x))u&=f(u(x))-f(0)
	\end{align*} 
	If $u$ solves (\ref{non-linear}), and if $f(0)\leq0$, then 
	\begin{align*}
		u_t-L u+f(u)-f(0) &\geq 0\\
		u_t-L u+ f'(\xi(x))u&\geq 0 \\
		u_t-L u+ c(x)u&\geq 0
	\end{align*}
	Hence the function $u$ is the super-solution to a (different) linear parabolic partial differential equation and hence we can apply the maximum principle \ref{maxprincprotterweinberger} and Hopf's boundary point lemma \ref{HopfBPL} to solutions of (\ref{non-linear}) as long as the other hypothesis apply to $c(x)$. 
\end{comment}
Secondly, we remind the reader of the following generalized version of the theorem of the mean, a.k.a. Lagrange's theorem:
\begin{theorem}[Lagrange's theorem]
	Given a convex open set $U\subseteq \R^n$ and a real function $F \in C^1(U)$, and given to points $x, y$ in $U$, there exists a point $z$ in the segment connecting $x$ and $y$ such that 
	\begin{align*}
		F(y)-F(x) =\left\langle \nabla F(z), (y-x) \right\rangle 
	\end{align*}
\end{theorem}
Suppose that we have a solution to a non-linear parabolic problem $v$, i.e. $v$ solves (\ref{nonlinearexample}):
\begin{align*}
	Lu= F\left(t, x, v, \frac{\partial v}{\partial x_i} , \frac{\partial^2 v}{\partial x_i \partial x_j}\right)-v_t = f(x, t)
\end{align*}
for a non-linear elliptic operator $L$ in some region $E$, where we assume $F(t, x, y_i, z_{i,j})$ to be a given $C^1$ function. Suppose also that there is a $w$ which is a solution of the corresponding differential inequality:
\begin{align*}
	Lw= F\left(t, x, w, \frac{\partial w}{\partial x_i} , \frac{\partial^2 w}{\partial x_i \partial x_j}\right)-w_t \leq f(x, t)
\end{align*}
One can then consider $u = v-w$, and by combining the above we get: 

\begin{align*}
	Lv= \left( F\left(t, x, v, \frac{\partial v}{\partial x_i} , \frac{\partial^2 v}{\partial x_i \partial x_j}\right) - F\left(t, x, w, \frac{\partial w}{\partial x_i} , \frac{\partial^2 w}{\partial x_i \partial x_j}\right)\right)-u_t \leq 0
\end{align*}

Now, we can apply Lagrange's theorem to $F$ to get 

\begin{align*}
	Lv= \left\langle \nabla F(\xi(x, t)), \left(t, x, u, \frac{\partial u}{\partial x_i} , \frac{\partial^2 u}{\partial x_i \partial x_j}\right) \right\rangle-u_t \leq 0
\end{align*}
for a fixed $\xi(x, t)$.


Thus, the difference $u$ of two sub-solutions to a non-linear differential problem is a sub-solution to a (different) \textit{linear} parabolic problem, as the derivatives of $F$ and $\xi$ do not depend on $u$ ($\xi$ can be chosen a-priori).

%An equivalent condition for a nonlinear problem to be parabolic is that for any real vector $\xi$
%\begin{align*}
%	\sum_{i, j=1}^n F_{ij}\xi_i\xi_j >0
%\end{align*} 
%where $F_{ij}$ are the derivatives of $F$ with respect to $\frac{\partial^2 v}{\partial x_i \partial x_j}$. 
We can thus see that this new problem must be parabolic, and apply the maximum principle and the Hopf's boundary point lemma to $u$. This can allow us to state the following two results which we will be using later:

\begin{proposition}[Maximum principle for parabolic non-linear differential equations]
	\label{firstapplication}
	Suppose we have two solution $v$ and $w$ in the interval $[0, T]$ to the same parabolic non-linear differential equation (\ref{nonlinearexample}) on an bounded open set $\Omega$, but with different start conditions. Suppose also that $F$ is smooth on  $\overline{\Omega}$. Then, if $v>w$ in the interior of $\Omega$ at $t=0$ and $v\geq w$ on $\partial\Omega$,  $v>w$ for all $t\in[0, T]$ in the interior of $\Omega$.
\end{proposition}

\begin{proof}
	$u=v-w\geq 0$ is a solution of a parabolic \textit{linear} differential equation, where the term independent of $u$ is bounded. Furthermore, if we take $c(x, t)$ it must be bounded by compactness. At $t=0$, $u>0$ in the interior of $\Omega$. If, at an interior point $x$, $v=w$ at a certain time $t=\tau$, $u(\tau, x)=0$, and thus $u$ is not constant. However, it attains minimum ($u=0$) at an interior point, thus by \ref{maximum_principle} it must be constant, a contradiction. 
\end{proof}

\begin{proposition}[Hopf's boundary point lemma for parabolic non-linear differential equations]
	\label{secondapplication}
	Suppose we have two solution $v$ and $w$ to the same parabolic non-linear differential equation (\ref{nonlinearexample}) in a region $E$, but with different start conditions. Suppose also that $F$ is smooth on  $\overline{\Omega}$. Let $u=v-w$ and suppose that the maximum of $u$ is attained at the point $P$. Furthermore, assume that the conditions on the shape of the region $E$ from theorem \ref{HopfBPL} hold. Then, 
	\begin{align*}
		\frac{\partial u}{\partial \nu}(P) >0
	\end{align*}
	where we take $\nu$ as the normal to $\partial\Omega$.
\end{proposition}

\begin{proof}
	$u$ is a solution of a parabolic \textit{linear} differential equation, where  $c(x, t)$ is bounded by compactness. We can then apply \ref{HopfBPL} to $v$ (see also remark \ref{removecpositive}).
\end{proof}

\section{Reflections on spheres and hyperbolic spaces}	

In what follows, we will focus on manifolds embedded in spaces which have constant sectional curvature. Constant curvature manifolds are classified into three types based on the sign of the curvature:
\begin{itemize}
	\item \textbf{Positive curvature}: \textit{Spherical geometry}, where the curvature is positive and the manifold locally resembles a sphere (e.g., the standard sphere $\mathbb{S}^n$).
	\item \textbf{Zero curvature}: \textit{Flat geometry}, where the curvature is zero and the manifold locally resembles Euclidean space $\mathbb{R}^n$.
	\item \textbf{Negative curvature}: \textit{Hyperbolic geometry}, where the curvature is negative and the manifold locally resembles hyperbolic space $\mathbb{H}^n$.
\end{itemize}

As in \cite{italiani}, we will use the symbol $\mathbb{M}^n$ to indicate a Riemannian manifold that can be replaced by any one of  $\mathbb{S}^n$, $\mathbb{R}^n$ or $\mathbb{H}^n$: the $n$-dimensional sphere, Euclidean plane or Hyperbolic space respectively. 

We will also use use the symbol $\mathbb{M}^n_+$ to indicate a Riemannian manifold that can be replaced by $\mathbb{S}^n_+$, $\mathbb{R}^n$ or $\mathbb{H}^n$: the $n$-dimensional hemisphere, Euclidean plane or Hyperbolic space, respectively


\begin{defin}
	$\mathbb{H}^n$
\end{defin}


\begin{oss}
	$\mathbb{H}^n$ - modello alternativo
\end{oss}

\begin{oss}
	Let $\mathbb{S}^n \setminus \{P\}$ be the standard $n$-dimensional unitary sphere minus a point, with the standard induced Euclidean metric. Through stereographic projection it is isometric to the 
\end{oss}

We will now construct the moving planes in $\mathbb{M}^n_+$:

{\vspace{10pt}\LARGE \bf [DA SCRIVERE]}

\section{The Method of the Moving Planes (da scrivere)}

To provide some justification and context to the next chapters, we describe Method of the Moving Planes in $\mathbb{M}^{n+1}_+$.  

Let $X:M^n\rightarrow \mathbb{M}^{n+1}_+$ be a hypersurface in a constant curvature ambient space. 



{\vspace{10pt}\LARGE \bf [DA SCRIVERE]}

\section{The Alexandrov soap-bubble theorem (da scrivere)}

To give some justification to the method we descrived, we will outline the proof an important result that uses this method, the so-called Alexandrov soap bubble theorem. For more details, see \cite{italiani}. 
{\vspace{10pt}\LARGE \bf [DA SCRIVERE]}
